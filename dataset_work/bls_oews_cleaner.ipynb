{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Bureau of Labor Statistics Occupational Employment and Wage Estimates by Metropolitan and Nonmetropolitan Area Data Cleaner\n",
    "\n",
    "The datasets are seperated by year, with each year having multiple `.xls` files where the different areas are split up. This notebook aims to clean the data from 2006-2024 by removing unwanted areas, and generating datasets separated by years and an overall dataset.\n",
    "\n",
    "We take data starting from 2006 since that is the earliest data by both metropolitan and nonmetropolitan area available, and we want to analyze the time range at which the job market affects college major choice. This enables us to plot up to the relationship between the 2006 job market and 2014 graduation majors (an 8 year difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes all xls files into csv files\n",
    "\n",
    "def xls_x_to_csv(file_path, file_type):\n",
    "    # Read the .xls file\n",
    "    df = pd.read_excel(file_path)\n",
    "    # Define the .csv file path\n",
    "    csv_file_path = file_path.replace(file_type, '.csv')\n",
    "    # Save the dataframe to a .csv file\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "def all_xls_x_to_csv(bls_data_path):\n",
    "    # Iterate over each year folder in the bls_data folder\n",
    "    for year_folder in os.listdir(bls_data_path):\n",
    "        if year_folder == \"full_processed_csvs\" or year_folder == \"useful_csvs\":\n",
    "            continue\n",
    "        year_path = os.path.join(bls_data_path, year_folder)\n",
    "        if os.path.isdir(year_path):\n",
    "            # Iterate over each .xls file in the year folder\n",
    "            for file in os.listdir(year_path):\n",
    "                if file.endswith('.xls'):\n",
    "                    file_path = os.path.join(year_path, file)\n",
    "                    xls_x_to_csv(file_path, '.xls')\n",
    "                if file.endswith('.xlsx'):\n",
    "                    file_path = os.path.join(year_path, file)\n",
    "                    xls_x_to_csv(file_path, '.xlsx')\n",
    "                    \n",
    "# Uncomment the line below to change all xls and xlsx files into csv files\n",
    "# all_xls_x_to_csv('bls_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to bls_data/full_processed_csvs/2013_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2014_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2022_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2023_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2015_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2012_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2008_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2006_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2007_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2009_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2017_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2010_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2019_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2021_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2020_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2018_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2011_relevant.csv\n",
      "Processed data saved to bls_data/full_processed_csvs/2016_relevant.csv\n"
     ]
    }
   ],
   "source": [
    "# Read through each year of csvs, and get only relevant areas into one csv\n",
    "relevant_areas = [\"Los Angeles-Long Beach-Santa Ana, CA\", \n",
    "\"Los Angeles-Long Beach-Anaheim, CA\", # shifts classification in 2015\n",
    "\"Western New Hampshire nonmetropolitan area\",\n",
    "\"Southwestern New Hampshire nonmetropolitan area\",\n",
    "\"West Central New Hampshire nonmetropolitan area\",\n",
    "\"Southwest New Hampshire nonmetropolitan area\",\n",
    "\"West Central-Southwest New Hampshire nonmetropolitan area\",\n",
    "\"San Diego-Carlsbad-San Marcos, CA\",\n",
    "\"San Diego-Carlsbad, CA\", # shifts classification in 2015\n",
    "\"Ann Arbor, MI\",\n",
    "\"Washington-Arlington-Alexandria, DC-VA-MD-WV Metropolitan Division\",\n",
    "\"Spokane, WA\",\n",
    "\"Spokane-Spokane Valley, WA\", # shifts classification in 2015\n",
    "\"Winston-Salem, NC\",\n",
    "\"Utica-Rome, NY\",\n",
    "]\n",
    "\n",
    "# All the relevant New Hampshire areas:\n",
    "# \"Other New Hampshire nonmetropolitan area\", - this means central - do not use\n",
    "# \"Western New Hampshire nonmetropolitan area\", - use\n",
    "# \"Southwestern New Hampshire nonmetropolitan area\", - use\n",
    "# \"West Central New Hampshire nonmetropolitan area\", - use - 2015\n",
    "# \"Central New Hampshire nonmetropolitan area\", - do not use - 2015\n",
    "# \"Southwest New Hampshire nonmetropolitan area\", - use - 2015\n",
    "# \"West Central-Southwest New Hampshire nonmetropolitan area\", - 2018 combination of west central and southwest - only choice aside from central in 2018 onwards\n",
    "# overall, we'll use West Central-Southwest, while avoiding Central?\n",
    "\n",
    "def process_year(bls_data_path, year_path, relevant_areas, column_name, year_number):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    processed_folder = os.path.join(bls_data_path, \"full_processed_csvs\")\n",
    "    os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through all CSV files in the year folder\n",
    "    for file in os.listdir(year_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(year_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            if column_name in df.columns:\n",
    "                # Filter rows where the column value is in relevant_areas\n",
    "                filtered_df = df[df[column_name].isin(relevant_areas)]\n",
    "                result_df = pd.concat([result_df, filtered_df], ignore_index=True)\n",
    "\n",
    "    # Define the output file path\n",
    "    output_file_path = os.path.join(processed_folder, f\"{year_number}_relevant.csv\")\n",
    "\n",
    "    # Write the filtered DataFrame to the output file\n",
    "    result_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"Processed data saved to {output_file_path}\")\n",
    "\n",
    "def process_all_years(bls_data_path, relevant_areas):\n",
    "    # Iterate over each year folder in the bls_data folder\n",
    "    for year_folder in os.listdir(bls_data_path):\n",
    "        if year_folder == \"full_processed_csvs\" or year_folder == \"useful_csvs\":\n",
    "            continue\n",
    "        year_number = int(year_folder)\n",
    "        year_path = os.path.join(bls_data_path, year_folder)\n",
    "        column_name = ''\n",
    "        if os.path.isdir(year_path):\n",
    "             # AREA_NAME 2006-2018, area_title in 2019, AREA_TITLE onwards\n",
    "            if year_number < 2019:\n",
    "                column_name = 'AREA_NAME'\n",
    "            elif year_number == 2019:\n",
    "                column_name = 'area_title'\n",
    "            elif year_number > 2019:\n",
    "                column_name = 'AREA_TITLE'\n",
    "            else:\n",
    "                print(\"Error: invalid year\")\n",
    "                exit(1)\n",
    "            process_year(bls_data_path, year_path, relevant_areas, column_name, year_number)\n",
    "\n",
    "process_all_years('bls_data', relevant_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format all area names and column names to be consistent, more cleaning done in next step\n",
    "\n",
    "def format_area_names(df):\n",
    "    if 'AREA_NAME' in df.columns:\n",
    "        df.rename(columns={'AREA_NAME': 'AREA_TITLE'}, inplace=True)\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"Los Angeles-Long Beach-Santa Ana, CA\", \"Los Angeles-Long Beach-Anaheim, CA\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"San Diego-Carlsbad-San Marcos, CA\", \"San Diego-Carlsbad, CA\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"Spokane, WA\", \"Spokane-Spokane Valley, WA\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"Western New Hampshire nonmetropolitan area\", \"West Central-Southwest New Hampshire nonmetropolitan area\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"Southwestern New Hampshire nonmetropolitan area\", \"West Central-Southwest New Hampshire nonmetropolitan area\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"West Central New Hampshire nonmetropolitan area\", \"West Central-Southwest New Hampshire nonmetropolitan area\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"Southwest New Hampshire nonmetropolitan area\", \"West Central-Southwest New Hampshire nonmetropolitan area\")\n",
    "    if 'GROUP' in df.columns:\n",
    "        df.rename(columns={'GROUP': 'OCC_GROUP'}, inplace=True)\n",
    "    elif 'O_GROUP' in df.columns:\n",
    "        df.rename(columns={'O_GROUP': 'OCC_GROUP'}, inplace=True)\n",
    "    if 'LOC QUOTIENT' in df.columns:\n",
    "        df.rename(columns={'LOC QUOTIENT': 'LOC_QUOTIENT'}, inplace=True)\n",
    "    if 'LOC_QUOTIENT' not in df.columns:\n",
    "        df['LOC_QUOTIENT'] = pd.NA\n",
    "    \n",
    "    return df\n",
    "\n",
    "def format_column_names(df):\n",
    "    for column in df.columns:\n",
    "        df.rename(columns={column: column.upper()}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def format_year(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = format_column_names(df)\n",
    "    df = format_area_names(df)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def format_all_years(processed_csv_path):\n",
    "    for file in os.listdir(processed_csv_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(processed_csv_path, file)\n",
    "            format_year(file_path)\n",
    "\n",
    "format_all_years('bls_data/full_processed_csvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish cleaning data by dropping useless columns\n",
    "\n",
    "def drop_useless_columns(df):\n",
    "    # Drop columns that are not needed\n",
    "    drop_list = ['AREA_TYPE', 'NAICS', 'NAICS_TITLE', 'I_GROUP', 'OWN_CODE', 'OCC_CODE', 'PCT_TOTAL', 'PCT_RPT', 'PRIM_STATE', 'AREA']\n",
    "    # OCC_CODE is the same as OCC_TITLE, PCT_TOTAL and PCT_RPT is always NaN, PRIM_STATE is in AREA_TITLE, AREA is same as AREA_TITLE, others cause issues\n",
    "    for column in drop_list:\n",
    "        if column in df.columns:\n",
    "            df.drop(columns=[column], inplace=True)\n",
    "    df.dropna(axis=1, how='all')\n",
    "    return df\n",
    "\n",
    "def drop_all_useless_columns(processed_csv_path):\n",
    "    for file in os.listdir(processed_csv_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(processed_csv_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            out_df = drop_useless_columns(df)\n",
    "            out_df.to_csv(os.path.join('bls_data/useful_csvs', file), index=False)\n",
    "\n",
    "drop_all_useless_columns('bls_data/full_processed_csvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check if all years have the same columns and if all areas are represented\n",
    "\n",
    "def test_csvs(useful_csv_path):\n",
    "    reference_columns = None\n",
    "    reference_area_titles = None\n",
    "    for file in os.listdir(useful_csv_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(useful_csv_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            if reference_columns is None:\n",
    "                reference_columns = set(df.columns)\n",
    "            else:\n",
    "                if set(df.columns) != reference_columns:\n",
    "                    print(f\"Warning: Columns in {file} do not match the reference columns.\")\n",
    "            if reference_area_titles is None:\n",
    "                reference_area_titles = set(df['AREA_TITLE'].unique())\n",
    "            else:\n",
    "                if set(df['AREA_TITLE'].unique()) != reference_area_titles:\n",
    "                    print(f\"Warning: Areas in {file} do not match the reference areas.\")\n",
    "            unique_area_titles = df['AREA_TITLE'].nunique()\n",
    "            if unique_area_titles != 8:\n",
    "                print(f\"Warning: {file} does not have all 8 areas represented.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all years into one csv\n",
    "\n",
    "def combine_years(useful_csv_path):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file in os.listdir(useful_csv_path):\n",
    "        if file.endswith('.csv') and file != 'all_years.csv':\n",
    "            file_path = os.path.join(useful_csv_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            year = int(file.split('_')[0])\n",
    "            df['YEAR'] = year\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    combined_df.dropna(axis=1, how='all')\n",
    "    column_order = ['YEAR', 'AREA_TITLE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP', 'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE', \n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10', 'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'ANNUAL', 'HOURLY']\n",
    "    combined_df = combined_df[column_order]\n",
    "    combined_df = combined_df.sort_values(by=['YEAR', 'AREA_TITLE'], ascending=[True, True], kind='mergesort')\n",
    "    combined_df.to_csv('bls_data/useful_csvs/all_years.csv', index=False)\n",
    "\n",
    "combine_years('bls_data/useful_csvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74580, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bls_data/useful_csvs/all_years.csv')\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
