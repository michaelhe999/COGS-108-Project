{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# School Common Data Set Degrees Conferred Data Cleaner\n",
    "\n",
    "The datasets are seperated by college, with each college having multiple `.pdfs` files for each academic year. This notebook aims to clean the data from 2014-2024 by scraping the pdf for the Degrees Conferred section, and generating datasets for each year the colleges, and overall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull degrees conferred tables from CDS PDFs\n",
    "\n",
    "def extract_table_from_pdf(pdf_path, pdf_name, full_processed_csvs_folder):\n",
    "    df_results = pd.DataFrame()\n",
    "    print(f\"Processing file {pdf_name}\")\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Iterate over the pages in the PDF\n",
    "        for page_num, page in enumerate(pdf.pages, start=1):\n",
    "            # Extract text content from the page\n",
    "            text = page.extract_text()\n",
    "            # Check if \"degrees conferred\" exists in the page text (case insensitive)\n",
    "            if \"degrees conferred\" in text.lower():\n",
    "                print(f\"Found 'degrees conferred' on page {page_num}. Extracting table...\")\n",
    "                tables = page.extract_tables()\n",
    "                for table in tables:\n",
    "                    df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                    df.columns = df.columns.str.replace('\\n', ' ', regex=True)\n",
    "                    df_results = pd.concat([df_results, df], ignore_index=True)\n",
    "                special_cases = [\"ucsd_2023\", \"wsu_2023\"]\n",
    "                extra_special_cases = [\"caltech_2021\", \"caltech_2022\", \"caltech_2023\", \"asu_2021\", \"asu_2022\", \"asu_2023\"]\n",
    "                if pdf_name in special_cases : # handle special case where table is split across two pages on a case-by-case basis\n",
    "                    next_page = pdf.pages[page_num]\n",
    "                    next_tables = next_page.extract_tables()\n",
    "                    if next_tables:\n",
    "                        for table in next_tables:\n",
    "                            df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                            top_row = df.columns\n",
    "                            df.columns = df_results.columns\n",
    "                            df.loc[-1] = top_row \n",
    "                            df.index = df.index + 1\n",
    "                            df = df.sort_index()\n",
    "                            df_results = pd.concat([df_results, df], ignore_index=True)\n",
    "                if pdf_name in extra_special_cases : # handle special case where table is split across two pages and the column names are on the second page\n",
    "                    next_page = pdf.pages[page_num]\n",
    "                    next_tables = next_page.extract_tables()\n",
    "                    if next_tables:\n",
    "                        for table in next_tables:\n",
    "                            df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                            df_results = pd.concat([df_results, df], ignore_index=True)\n",
    "                break\n",
    "        if df_results.empty:\n",
    "            print(f\"'degrees conferred' not found in page {page_num}.\")\n",
    "\n",
    "    if not df_results.empty:\n",
    "        df_results = df_results.reset_index(drop=True)\n",
    "        year_directory = os.path.join(full_processed_csvs_folder, pdf_name.split(\"_\")[1])\n",
    "        if not os.path.exists(year_directory):\n",
    "            os.makedirs(year_directory)\n",
    "        file_name = os.path.join(year_directory, f\"{pdf_name}_degrees_conferred.csv\")\n",
    "        df_results.to_csv(file_name, index=False)\n",
    "        print(f\"Table saved to {file_name}.\")\n",
    "\n",
    "def extract_all_tables(cds_data_folder, full_processed_csvs_folder):\n",
    "    for college_folder in os.listdir(cds_data_folder):\n",
    "        if college_folder == \"full_processed_csvs\" or college_folder == \"useful_csvs\" or college_folder == \".DS_Store\" or college_folder == \"manual\":\n",
    "            continue\n",
    "        college_folder_path = os.path.join(cds_data_folder, college_folder)\n",
    "        for pdf_file in os.listdir(college_folder_path):\n",
    "            if pdf_file.endswith('.pdf'):\n",
    "                pdf_file_path = os.path.join(college_folder_path, pdf_file)\n",
    "                extract_table_from_pdf(pdf_file_path, pdf_file.split(\".\")[0], full_processed_csvs_folder)\n",
    "\n",
    "extract_all_tables(\"cds_data\", \"cds_data/full_processed_csvs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean datasets by merging columns with similar names and combining data from different years\n",
    "\n",
    "def merge_column_names(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if \"Diploma/ Certificates\" in df.columns:\n",
    "        df = df.rename(columns={\"Diploma/ Certificates\": \"Diploma/Certificates\"})\n",
    "    elif \"Diplomas / Certificates\" in df.columns:\n",
    "        df = df.rename(columns={\"Diplomas / Certificates\": \"Diploma/Certificates\"})\n",
    "    elif \"\\\"Diploma/\\nCertificates\\\"\" in df.columns:\n",
    "        df = df.rename(columns={\"\\\"Diploma/\\nCertificates\\\"\": \"Diploma/Certificates\"})\n",
    "    if \"CIP 2010 Categories to Include\" in df.columns:\n",
    "        df = df.rename(columns={\"CIP 2010 Categories to Include\": \"CIP Code\"})\n",
    "    elif \"CIP Code Number\" in df.columns:\n",
    "        df = df.rename(columns={\"CIP Code Number\": \"CIP Code\"})\n",
    "    elif \"CIP 2020 Categories to Include\" in df.columns:\n",
    "        df = df.rename(columns={\"CIP 2020 Categories to Include\": \"CIP Code\"})\n",
    "    elif \"CIP 2021 Categories to Include\" in df.columns:\n",
    "        df = df.rename(columns={\"CIP 2021 Categories to Include\": \"CIP Code\"})\n",
    "    elif \"CIP202 Categories to Include\" in df.columns:\n",
    "        df = df.rename(columns={\"CIP202 Categories to Include\": \"CIP Code\"})\n",
    "    elif \"\\\"CIP202\\nCategories\\nto\\nInclude\\\"\" in df.columns:\n",
    "        df = df.rename(columns={\"\\\"CIP202\\nCategories\\nto\\nInclude\\\"\": \"CIP Code\"})\n",
    "    if \"Category (UM-Ann Arbor grants Bachelor's degrees; no undergraduate Diploma/Certificates or Associate degrees)\" in df.columns:\n",
    "        df = df.rename(columns={\"Category (UM-Ann Arbor grants Bachelor's degrees; no undergraduate Diploma/Certificates or Associate degrees)\": \"Category\"})\n",
    "    if \"Unnamed: 2\" in df.columns:\n",
    "        df = df.rename(columns={\"Unnamed: 2\": \"Bachelor's\"})\n",
    "    if \"Bachelor’s degrees (First majors)\" in df.columns:\n",
    "        df = df.drop(columns=[\"Bachelor’s degrees (First majors)\"])\n",
    "    return df\n",
    "    \n",
    "def merge_all_column_names(full_processed_csvs_folder):\n",
    "    for year_folder in os.listdir(full_processed_csvs_folder):\n",
    "        if year_folder == \".DS_Store\" or year_folder == \"combined\":\n",
    "            continue\n",
    "        year_folder_path = os.path.join(full_processed_csvs_folder, year_folder)\n",
    "        for college_file in os.listdir(year_folder_path):\n",
    "            if college_file.endswith('.csv'):\n",
    "                college_file_path = os.path.join(year_folder_path, college_file)\n",
    "                df = merge_column_names(college_file_path)\n",
    "                df.to_csv(college_file_path, index=False)\n",
    "\n",
    "def combine_year_data(full_processed_csvs_folder):\n",
    "    for year_folder in os.listdir(full_processed_csvs_folder):\n",
    "        if year_folder == \".DS_Store\" or year_folder == \"combined\":\n",
    "            continue\n",
    "        year_folder_path = os.path.join(full_processed_csvs_folder, year_folder)\n",
    "        combined_df = pd.DataFrame()\n",
    "        for college_file in os.listdir(year_folder_path):\n",
    "            if college_file.endswith('.csv'):\n",
    "                college_file_path = os.path.join(year_folder_path, college_file)\n",
    "                df = pd.read_csv(college_file_path)\n",
    "                df[\"college\"] = college_file.split(\"_\")[0]\n",
    "                df[\"year\"] = year_folder\n",
    "                combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "        combined_folder = \"cds_data/useful_csvs\"\n",
    "        if not os.path.exists(combined_folder):\n",
    "            os.makedirs(combined_folder)\n",
    "        combined_df.to_csv(os.path.join(combined_folder, f\"{year_folder}_combined.csv\"), index=False)\n",
    "\n",
    "merge_all_column_names(\"cds_data/full_processed_csvs\")\n",
    "combine_year_data(\"cds_data/full_processed_csvs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix UMich data :///\n",
    "for combined_csv in os.listdir(\"cds_data/useful_csvs\"):\n",
    "    df = pd.read_csv(os.path.join(\"cds_data/useful_csvs\", combined_csv))\n",
    "    df.replace(\"--\", \"\", inplace=True)\n",
    "    if \"Bachelor's\" in df.columns:\n",
    "        df['Bachelor’s'] = df['Bachelor’s'].combine_first(df[\"Bachelor's\"])\n",
    "        df = df.drop(columns=[\"Bachelor's\"])\n",
    "    df.to_csv(os.path.join(\"cds_data/useful_csvs\", combined_csv), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data from different years into a single dataset\n",
    "\n",
    "def combine_years(useful_csv_path):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file in os.listdir(useful_csv_path):\n",
    "        if file.endswith('.csv') and file != 'all_years.csv':\n",
    "            file_path = os.path.join(useful_csv_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    combined_df.dropna(axis=1, how='all')\n",
    "    column_order = ['year', 'college', 'CIP Code', 'Category', 'Bachelor’s', 'Associate', 'Diploma/Certificates']\n",
    "    combined_df = combined_df[column_order]\n",
    "    combined_df = combined_df.sort_values(by=['year', 'college'], ascending=[True, True], kind='mergesort')\n",
    "    combined_df.to_csv('cds_data/useful_csvs/all_years.csv', index=False)\n",
    "\n",
    "combine_years('cds_data/useful_csvs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
