{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - EDA Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Michael He\n",
    "- Felicia Zhang\n",
    "- Dhiren Patel\n",
    "- Sarah Li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do national and local job market trends (measured by the number of jobs across the nation and in certain metropolitan areas) influence the selection of majors among undergraduate students at UCSD and other selected universities across the nation? What is more influential, the national or local job market, and which years prior to graduation are most influential on major choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can easily be stated that people go to college in order to get a job after graduation. Since the major that students graduate with affect the industry they can work in after graduation, it seems like a natural assumption that the job market has some effect on what subject students choose to major in. \n",
    "\n",
    "Research has been done on similar topics; Baker et. al posits that community college graduates are about 1.5% more likely to choose a major that corresponds with a 1% increase in salary <a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1). Utilizing logit models to estimate the probabilities of different major selections and Ordinary Least Squares to model the relationship between major choice, employment security, and salary expectations, the paper concludes that community college students have less access to accurate job market information, and thus mostly consider course enjoyment, while barely considering employment probability. \n",
    "\n",
    "Similarly, Long et. al find that college majors are most strongly tied to salaries from 3 years before graduation (when most students have to choose their major) <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2). Their analysis covered both national and state (Washington) wage and major trends, using regression models to estimate the association between major choice and wage rates from a few years ago. They also used Granger causality tests to measure if previous data on wages were predictive of major choice. \n",
    "\n",
    "Despite there being a lot of research tying the job market to student major choices, we found little research analyzing the effects of employment rates in various industry sectors on major choice. We also aim to analyze a wider range of factors, covering different university locations and university types (public vs. private). This is because we’ve seen some research show that location affects college education, but not necessarily the major distributions at those locations <a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3). While we have seen that the job market has significant influence on major choices, we aim to discover the timeframe between the job market and major effects, as well as if the local or national job market has more influence.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [1](#cite_ref-1) Baker, Rachel, et al. The Effect of Labor Market Information on Community College Students’ Major Choice, ScienceDirect, Aug. 2018, [edpolicy.umich.edu/sites/epi/files/uploads/02-2017-labor-market-major-choice.pdf](https://edpolicy.umich.edu/sites/epi/files/uploads/02-2017-labor-market-major-choice.pdf)\n",
    "2. <a name=\"cite_note-2\"></a> [2](#cite_ref-2) Long et. al Do Students’ College Major Choices Respond to Changes in Wages, Calder Center, January 2014, [https://caldercenter.org/sites/default/files/WP-107.pdf](https://caldercenter.org/sites/default/files/WP-107.pdf)\n",
    "3. <a name=\"cite_note-3\"></a> [3](#cite_ref-3) Higdon, Why does college location matter, April 2017, [https://www.northcentral.edu/blog/why-does-college-location-matter/](https://www.northcentral.edu/blog/why-does-college-location-matter/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict that undergraduate major students are influenced by job market trends, with the strongest correlation between the majors students select and the job market conditions from approximately 4 years prior to when they first enter college. Specifically, we believe that national job market trends, such as wage growth and demand within central industries (e.g., healthcare, technology), will show a strong correlation with the selection of undergraduate majors across the United States. Furthermore, local job market trends, including employment opportunities and industry-specific demand will have a stronger influence on the major selection at universities such as UCSD, where students are more prone to aligning their academic focus with the region’s economic landscape.\n",
    "\n",
    "For this study, we would define major choice as the number of individuals who graduated with the major (or a similar one), and job market trends as the number of jobs in that field. Since our background research shows that factors such as wages affect major choice, it can be assumed that the increased possibility of finding a job in that field (which would lead to the receiving wages in the first place), would also be a factor in people’s major decision. We believe that these two variables would have a positive correlation — as the number of jobs in a certain field increases, so does the number of college students who choose a related major."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "- Dataset #1\n",
    "  - Dataset Name: US Bureau of Labor Statistics Occupational Employment and Wage Estimates by Metropolitan and Nonmetropolitan Area (BLS OEWS for short)\n",
    "  - Link to the dataset: [BLS OEWS](https://www.bls.gov/oes/tables.htm)\n",
    "  - Cleaned dataset: [all_year_bls](dataset_work/bls_data/useful_csvs/all_years.csv)\n",
    "  - Number of observations: 74580\n",
    "  - Number of variables: 23\n",
    "- Dataset #2 \n",
    "  - Dataset Name: School Common Data Set Degrees Conferred (CDS for short)\n",
    "  - Link to the dataset: [CDS](https://docs.google.com/spreadsheets/d/19kN52hyig4k--l1GXVEiIQVoSM10L_shYSVXepYsSDM/edit?usp=sharing)\\\n",
    "  This is actually a link to a Google Sheet, where you can find the link to each school's CDS\\\n",
    "  - Cleaned dataset: [all_year_csd](dataset_work/cds_data/useful_csvs/all_years.csv)\n",
    "  - Number of observations: 3092\n",
    "  - Number of variables: 7\n",
    "\n",
    "#### BLS OEWS:\n",
    "This dataset encompasses 2006-2023 employment data by metropolitan/non-metropolitan area. Our cleaned dataset has 8 areas, each of which were chosen because of their proximity to one of the schools we are analyzing. The important variables in the data set are year, location, occupation title (string), total employment (int), and average salary (int), although the other fields we left in the dataset also help with general analysis and classification. The employment count proportion and the salary may be proxies for overall desirability of the job. \n",
    "\n",
    "To clean this dataset, we had to download all the `.xls` and `.xlsx` files from the BLS, convert them to `.csv`s, and then pull only the relevant areas from each year's dataset. Then, to combine the datasets and standardize the columns, some columns were dropped or renamed, leading to the overall dataset. \n",
    "\n",
    "#### CDS:\n",
    "This dataset encompasses 8 US universities, which were chosen for reasons listed in our [Google Sheet](https://docs.google.com/spreadsheets/d/19kN52hyig4k--l1GXVEiIQVoSM10L_shYSVXepYsSDM/edit?usp=sharing). The most limiting university was Colgate University, with the first CDS being from 2014, so the years span from 2014 graduation to 2023 graduation degrees conferred. This gives us a good 10 year window to work with. The important variables in this dataset are year, college, Category (major), and Bachelor's (a percentage of the graduating class). The major percentages may be proxies for the overall desirability of the major. \n",
    "\n",
    "To clean this dataset, we had to download all the `.pdf` files of the CDS from each school. We then created and ran a pdf scraper to pull the Degrees Conferred table from each PDF; there were a few cases where this had to be done manually because of inconsistent formatting or lack of downloadable PDF. Then, to combine the datasets, equivalent columns were combined, leading to the overall dataset.\n",
    "\n",
    "##### Combining\n",
    "To combine these datasets, it's necessary to line up majors at colleges with jobs. This means we will probably use a classifier to fit the jobs in 'OCC-TITLE' to the majors in 'Category'. Then, we can graph the relationships between employment rates and major trends. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLS OEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes all xls files into csv files\n",
    "\n",
    "def xls_x_to_csv(file_path, file_type):\n",
    "    # Read the .xls file\n",
    "    df = pd.read_excel(file_path)\n",
    "    # Define the .csv file path\n",
    "    csv_file_path = file_path.replace(file_type, '.csv')\n",
    "    # Save the dataframe to a .csv file\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "def all_xls_x_to_csv(bls_data_path):\n",
    "    # Iterate over each year folder in the bls_data folder\n",
    "    for year_folder in os.listdir(bls_data_path):\n",
    "        if year_folder == \"full_processed_csvs\" or year_folder == \"useful_csvs\":\n",
    "            continue\n",
    "        year_path = os.path.join(bls_data_path, year_folder)\n",
    "        if os.path.isdir(year_path):\n",
    "            # Iterate over each .xls file in the year folder\n",
    "            for file in os.listdir(year_path):\n",
    "                if file.endswith('.xls'):\n",
    "                    file_path = os.path.join(year_path, file)\n",
    "                    xls_x_to_csv(file_path, '.xls')\n",
    "                if file.endswith('.xlsx'):\n",
    "                    file_path = os.path.join(year_path, file)\n",
    "                    xls_x_to_csv(file_path, '.xlsx')\n",
    "                    \n",
    "# Uncomment the line below to change all xls and xlsx files into csv files\n",
    "# all_xls_x_to_csv('dataset_work/bls_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2013_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2014_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2022_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2023_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2015_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2012_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2008_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2006_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2007_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2009_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2017_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2010_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2019_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2021_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2020_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2018_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2011_relevant.csv\n",
      "Processed data saved to dataset_work/bls_data/full_processed_csvs/2016_relevant.csv\n"
     ]
    }
   ],
   "source": [
    "# Read through each year of csvs, and get only relevant areas into one csv\n",
    "relevant_areas = [\"Los Angeles-Long Beach-Santa Ana, CA\", \n",
    "\"Los Angeles-Long Beach-Anaheim, CA\", # shifts classification in 2015\n",
    "\"Western New Hampshire nonmetropolitan area\",\n",
    "\"Southwestern New Hampshire nonmetropolitan area\",\n",
    "\"West Central New Hampshire nonmetropolitan area\",\n",
    "\"Southwest New Hampshire nonmetropolitan area\",\n",
    "\"West Central-Southwest New Hampshire nonmetropolitan area\",\n",
    "\"San Diego-Carlsbad-San Marcos, CA\",\n",
    "\"San Diego-Carlsbad, CA\", # shifts classification in 2015\n",
    "\"Ann Arbor, MI\",\n",
    "\"Washington-Arlington-Alexandria, DC-VA-MD-WV Metropolitan Division\",\n",
    "\"Spokane, WA\",\n",
    "\"Spokane-Spokane Valley, WA\", # shifts classification in 2015\n",
    "\"Winston-Salem, NC\",\n",
    "\"Utica-Rome, NY\",\n",
    "]\n",
    "\n",
    "# All the relevant New Hampshire areas:\n",
    "# \"Other New Hampshire nonmetropolitan area\", - this means central - do not use\n",
    "# \"Western New Hampshire nonmetropolitan area\", - use\n",
    "# \"Southwestern New Hampshire nonmetropolitan area\", - use\n",
    "# \"West Central New Hampshire nonmetropolitan area\", - use - 2015\n",
    "# \"Central New Hampshire nonmetropolitan area\", - do not use - 2015\n",
    "# \"Southwest New Hampshire nonmetropolitan area\", - use - 2015\n",
    "# \"West Central-Southwest New Hampshire nonmetropolitan area\", - 2018 combination of west central and southwest - only choice aside from central in 2018 onwards\n",
    "# overall, we'll use West Central-Southwest, while avoiding Central?\n",
    "\n",
    "def process_year(bls_data_path, year_path, relevant_areas, column_name, year_number):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    processed_folder = os.path.join(bls_data_path, \"full_processed_csvs\")\n",
    "    os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through all CSV files in the year folder\n",
    "    for file in os.listdir(year_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(year_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            if column_name in df.columns:\n",
    "                # Filter rows where the column value is in relevant_areas\n",
    "                filtered_df = df[df[column_name].isin(relevant_areas)]\n",
    "                result_df = pd.concat([result_df, filtered_df], ignore_index=True)\n",
    "\n",
    "    # Define the output file path\n",
    "    output_file_path = os.path.join(processed_folder, f\"{year_number}_relevant.csv\")\n",
    "\n",
    "    # Write the filtered DataFrame to the output file\n",
    "    result_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"Processed data saved to {output_file_path}\")\n",
    "\n",
    "def process_all_years(bls_data_path, relevant_areas):\n",
    "    # Iterate over each year folder in the bls_data folder\n",
    "    for year_folder in os.listdir(bls_data_path):\n",
    "        if year_folder == \"full_processed_csvs\" or year_folder == \"useful_csvs\":\n",
    "            continue\n",
    "        year_number = int(year_folder)\n",
    "        year_path = os.path.join(bls_data_path, year_folder)\n",
    "        column_name = ''\n",
    "        if os.path.isdir(year_path):\n",
    "             # AREA_NAME 2006-2018, area_title in 2019, AREA_TITLE onwards\n",
    "            if year_number < 2019:\n",
    "                column_name = 'AREA_NAME'\n",
    "            elif year_number == 2019:\n",
    "                column_name = 'area_title'\n",
    "            elif year_number > 2019:\n",
    "                column_name = 'AREA_TITLE'\n",
    "            else:\n",
    "                print(\"Error: invalid year\")\n",
    "                exit(1)\n",
    "            process_year(bls_data_path, year_path, relevant_areas, column_name, year_number)\n",
    "\n",
    "process_all_years('dataset_work/bls_data', relevant_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format all area names and column names to be consistent, more cleaning done in next step\n",
    "\n",
    "def format_area_names(df):\n",
    "    if 'AREA_NAME' in df.columns:\n",
    "        df.rename(columns={'AREA_NAME': 'AREA_TITLE'}, inplace=True)\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"Los Angeles-Long Beach-Santa Ana, CA\", \"Los Angeles-Long Beach-Anaheim, CA\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"San Diego-Carlsbad-San Marcos, CA\", \"San Diego-Carlsbad, CA\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"Spokane, WA\", \"Spokane-Spokane Valley, WA\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"Western New Hampshire nonmetropolitan area\", \"West Central-Southwest New Hampshire nonmetropolitan area\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"Southwestern New Hampshire nonmetropolitan area\", \"West Central-Southwest New Hampshire nonmetropolitan area\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"West Central New Hampshire nonmetropolitan area\", \"West Central-Southwest New Hampshire nonmetropolitan area\")\n",
    "    df['AREA_TITLE'] = df['AREA_TITLE'].replace(\"Southwest New Hampshire nonmetropolitan area\", \"West Central-Southwest New Hampshire nonmetropolitan area\")\n",
    "    if 'GROUP' in df.columns:\n",
    "        df.rename(columns={'GROUP': 'OCC_GROUP'}, inplace=True)\n",
    "    elif 'O_GROUP' in df.columns:\n",
    "        df.rename(columns={'O_GROUP': 'OCC_GROUP'}, inplace=True)\n",
    "    if 'LOC QUOTIENT' in df.columns:\n",
    "        df.rename(columns={'LOC QUOTIENT': 'LOC_QUOTIENT'}, inplace=True)\n",
    "    if 'LOC_QUOTIENT' not in df.columns:\n",
    "        df['LOC_QUOTIENT'] = pd.NA\n",
    "    \n",
    "    return df\n",
    "\n",
    "def format_column_names(df):\n",
    "    for column in df.columns:\n",
    "        df.rename(columns={column: column.upper()}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def format_year(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = format_column_names(df)\n",
    "    df = format_area_names(df)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def format_all_years(processed_csv_path):\n",
    "    for file in os.listdir(processed_csv_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(processed_csv_path, file)\n",
    "            format_year(file_path)\n",
    "\n",
    "format_all_years('dataset_work/bls_data/full_processed_csvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish cleaning data by dropping useless columns\n",
    "\n",
    "def drop_useless_columns(df):\n",
    "    # Drop columns that are not needed\n",
    "    drop_list = ['AREA_TYPE', 'NAICS', 'NAICS_TITLE', 'I_GROUP', 'OWN_CODE', 'OCC_CODE', 'PCT_TOTAL', 'PCT_RPT', 'PRIM_STATE', 'AREA']\n",
    "    # OCC_CODE is the same as OCC_TITLE, PCT_TOTAL and PCT_RPT is always NaN, PRIM_STATE is in AREA_TITLE, AREA is same as AREA_TITLE, others cause issues\n",
    "    for column in drop_list:\n",
    "        if column in df.columns:\n",
    "            df.drop(columns=[column], inplace=True)\n",
    "    df.dropna(axis=1, how='all')\n",
    "    return df\n",
    "\n",
    "def drop_all_useless_columns(processed_csv_path):\n",
    "    for file in os.listdir(processed_csv_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(processed_csv_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            out_df = drop_useless_columns(df)\n",
    "            out_df.to_csv(os.path.join('dataset_work/bls_data/useful_csvs', file), index=False)\n",
    "\n",
    "drop_all_useless_columns('dataset_work/bls_data/full_processed_csvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check if all years have the same columns and if all areas are represented\n",
    "\n",
    "def test_csvs(useful_csv_path):\n",
    "    reference_columns = None\n",
    "    reference_area_titles = None\n",
    "    for file in os.listdir(useful_csv_path):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(useful_csv_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            if reference_columns is None:\n",
    "                reference_columns = set(df.columns)\n",
    "            else:\n",
    "                if set(df.columns) != reference_columns:\n",
    "                    print(f\"Warning: Columns in {file} do not match the reference columns.\")\n",
    "            if reference_area_titles is None:\n",
    "                reference_area_titles = set(df['AREA_TITLE'].unique())\n",
    "            else:\n",
    "                if set(df['AREA_TITLE'].unique()) != reference_area_titles:\n",
    "                    print(f\"Warning: Areas in {file} do not match the reference areas.\")\n",
    "            unique_area_titles = df['AREA_TITLE'].nunique()\n",
    "            if unique_area_titles != 8:\n",
    "                print(f\"Warning: {file} does not have all 8 areas represented.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all years into one csv\n",
    "\n",
    "def combine_years(useful_csv_path):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file in os.listdir(useful_csv_path):\n",
    "        if file.endswith('.csv') and file != 'all_years.csv':\n",
    "            file_path = os.path.join(useful_csv_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            year = int(file.split('_')[0])\n",
    "            df['YEAR'] = year\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    combined_df.dropna(axis=1, how='all')\n",
    "    column_order = ['YEAR', 'AREA_TITLE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP', 'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE', \n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10', 'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'ANNUAL', 'HOURLY']\n",
    "    combined_df = combined_df[column_order]\n",
    "    combined_df = combined_df.sort_values(by=['YEAR', 'AREA_TITLE'], ascending=[True, True], kind='mergesort')\n",
    "    combined_df.to_csv('dataset_work/bls_data/useful_csvs/all_years.csv', index=False)\n",
    "\n",
    "combine_years('dataset_work/bls_data/useful_csvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF shape: + (74580, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>AREA_TITLE</th>\n",
       "      <th>OCC_TITLE</th>\n",
       "      <th>OCC_GROUP</th>\n",
       "      <th>TOT_EMP</th>\n",
       "      <th>EMP_PRSE</th>\n",
       "      <th>JOBS_1000</th>\n",
       "      <th>LOC_QUOTIENT</th>\n",
       "      <th>H_MEAN</th>\n",
       "      <th>A_MEAN</th>\n",
       "      <th>...</th>\n",
       "      <th>H_MEDIAN</th>\n",
       "      <th>H_PCT75</th>\n",
       "      <th>H_PCT90</th>\n",
       "      <th>A_PCT10</th>\n",
       "      <th>A_PCT25</th>\n",
       "      <th>A_MEDIAN</th>\n",
       "      <th>A_PCT75</th>\n",
       "      <th>A_PCT90</th>\n",
       "      <th>ANNUAL</th>\n",
       "      <th>HOURLY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>Ann Arbor, MI</td>\n",
       "      <td>All Occupations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197810</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.29</td>\n",
       "      <td>46370</td>\n",
       "      <td>...</td>\n",
       "      <td>18.26</td>\n",
       "      <td>27.99</td>\n",
       "      <td>39.96</td>\n",
       "      <td>17710</td>\n",
       "      <td>24330</td>\n",
       "      <td>37970</td>\n",
       "      <td>58220</td>\n",
       "      <td>83120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>Ann Arbor, MI</td>\n",
       "      <td>Management occupations</td>\n",
       "      <td>major</td>\n",
       "      <td>8060</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.54</td>\n",
       "      <td>94720</td>\n",
       "      <td>...</td>\n",
       "      <td>41.80</td>\n",
       "      <td>56.95</td>\n",
       "      <td>#</td>\n",
       "      <td>43940</td>\n",
       "      <td>59410</td>\n",
       "      <td>86940</td>\n",
       "      <td>118450</td>\n",
       "      <td>#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>Ann Arbor, MI</td>\n",
       "      <td>Chief executives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>540</td>\n",
       "      <td>9.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.39</td>\n",
       "      <td>158890</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>92220</td>\n",
       "      <td>121340</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>Ann Arbor, MI</td>\n",
       "      <td>General and operations managers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1670</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.89</td>\n",
       "      <td>97530</td>\n",
       "      <td>...</td>\n",
       "      <td>41.20</td>\n",
       "      <td>59.33</td>\n",
       "      <td>#</td>\n",
       "      <td>46290</td>\n",
       "      <td>58170</td>\n",
       "      <td>85690</td>\n",
       "      <td>123400</td>\n",
       "      <td>#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>Ann Arbor, MI</td>\n",
       "      <td>Legislators</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>...</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR     AREA_TITLE                        OCC_TITLE OCC_GROUP TOT_EMP  \\\n",
       "0  2006  Ann Arbor, MI                  All Occupations       NaN  197810   \n",
       "1  2006  Ann Arbor, MI           Management occupations     major    8060   \n",
       "2  2006  Ann Arbor, MI                 Chief executives       NaN     540   \n",
       "3  2006  Ann Arbor, MI  General and operations managers       NaN    1670   \n",
       "4  2006  Ann Arbor, MI                      Legislators       NaN      30   \n",
       "\n",
       "  EMP_PRSE JOBS_1000 LOC_QUOTIENT H_MEAN  A_MEAN  ... H_MEDIAN H_PCT75  \\\n",
       "0      1.5       NaN          NaN  22.29   46370  ...    18.26   27.99   \n",
       "1      3.7       NaN          NaN  45.54   94720  ...    41.80   56.95   \n",
       "2      9.6       NaN          NaN  76.39  158890  ...        #       #   \n",
       "3      6.1       NaN          NaN  46.89   97530  ...    41.20   59.33   \n",
       "4     27.0       NaN          NaN      *       *  ...        *       *   \n",
       "\n",
       "  H_PCT90 A_PCT10 A_PCT25 A_MEDIAN A_PCT75 A_PCT90 ANNUAL HOURLY  \n",
       "0   39.96   17710   24330    37970   58220   83120    NaN    NaN  \n",
       "1       #   43940   59410    86940  118450       #    NaN    NaN  \n",
       "2       #   92220  121340        #       #       #    NaN    NaN  \n",
       "3       #   46290   58170    85690  123400       #    NaN    NaN  \n",
       "4       *       *       *        *       *       *   True    NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_work/bls_data/useful_csvs/all_years.csv')\n",
    "print(f\"DF shape: + {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2 (if you have more than one, use name instead of number here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "Carry out whatever EDA you need to for your project.  Because every project will be different we can't really give you much of a template at this point. But please make sure you describe the what and why in text here as well as providing interpretation of results and context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 of EDA - please give it a better title than this\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 of EDA if you need it  - please give it a better title than this\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thoughtful discussion of ethical concerns included\n",
    "- Ethical concerns consider the whole data science process (question asked, data collected, data being used, the bias in data, analysis, post-analysis, etc.)\n",
    "- How your group handled bias/ethical concerns clearly described\n",
    "\n",
    "Acknowledge and address any ethics & privacy related issues of your question(s), proposed dataset(s), and/or analyses. Use the information provided in lecture to guide your group discussion and thinking. If you need further guidance, check out [Deon's Ethics Checklist](http://deon.drivendata.org/#data-science-ethics-checklist). In particular:\n",
    "\n",
    "- Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?)\n",
    "- How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "- Are there any other issues related to your topic area, data, and/or analyses that are potentially problematic in terms of data privacy and equitable impact?\n",
    "- How will you handle issues you identified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Read over the [COGS108 Team Policies](https://github.com/COGS108/Projects/blob/master/COGS108_TeamPolicies.md) individually. Then, include your group’s expectations of one another for successful completion of your COGS108 project below. Discuss and agree on what all of your expectations are. Discuss how your team will communicate throughout the quarter and consider how you will communicate respectfully should conflicts arise. By including each member’s name above and by adding their name to the submission, you are indicating that you have read the COGS108 Team Policies, accept your team’s expectations below, and have every intention to fulfill them. These expectations are for your team’s use and benefit — they won’t be graded for their details.\n",
    "\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your team's specific project timeline. An example timeline has been provided. Changes the dates, times, names, and details to fit your group's plan.\n",
    "\n",
    "If you think you will need any special resources or training outside what we have covered in COGS 108 to solve your problem, then your proposal should state these clearly. For example, if you have selected a problem that involves implementing multiple neural networks, please state this so we can make sure you know what you’re doing and so we can point you to resources you will need to implement your project. Note that you are not required to use outside methods.\n",
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data (Ant Man); EDA (Hulk) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin Analysis (Iron Man; Thor) | Discuss/edit Analysis; Complete project check-in |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Wasp)| Discuss/edit full project |\n",
    "| 3/20  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
